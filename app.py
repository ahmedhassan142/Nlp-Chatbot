import gradio as gr
from inference import UrduSentimentPredictor
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize predictor - automatically falls back to bert-base-multilingual-cased
predictor = UrduSentimentPredictor()

def format_response(prediction):
    """Standardize API response format"""
    if prediction.get("success"):
        return {
            "sentiment": prediction["sentiment"].title(),  # Capitalize (Positive/Negative)
            "confidence": f"{float(prediction['confidence']) * 100:.1f}%",
            "success": True
        }
    return {
        "error": prediction.get("error", "Unknown error"),
        "success": False
    }

def analyze(text):
    """Handle prediction with comprehensive error handling"""
    if not text.strip():
        return {"error": "Input text cannot be empty", "success": False}
    
    try:
        prediction = predictor.predict(text)
        return format_response(prediction)
    except Exception as e:
        logger.error(f"Prediction failed: {str(e)}")
        return {"error": str(e), "success": False}

# Gradio interface with improved UI
demo = gr.Interface(
    fn=analyze,
    inputs=gr.Textbox(
        label="ğŸ”¤ Ø§Ø±Ø¯Ùˆ Ù…ØªÙ† Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº", 
        placeholder="Ù…Ø«Ø§Ù„: ÛŒÛ ÙÙ„Ù… Ø¨ÛØª Ø§Ú†Ú¾ÛŒ ØªÚ¾ÛŒ...",
        lines=3
    ),
    outputs=[
        gr.Label(label="Ø¬Ø°Ø¨Ø§Øª"),
        gr.Label(label="Ø§Ø¹ØªÙ…Ø§Ø¯"),
        gr.Textbox(label="ØªÙØµÛŒÙ„Ø§Øª", visible=False)  # Hidden for error cases
    ],
    title="ğŸ‡µğŸ‡° Ø§Ø±Ø¯Ùˆ Ø¬Ø°Ø¨Ø§ØªÛŒ ØªØ¬Ø²ÛŒÛ",
    description="Ø¨Ø±Ù¹ Ù…Ø§ÚˆÙ„ Ú©ÛŒ Ù…Ø¯Ø¯ Ø³Û’ Ø§Ø±Ø¯Ùˆ Ù…ØªÙ† Ú©Û’ Ø¬Ø°Ø¨Ø§Øª Ú©Ø§ ØªØ¬Ø²ÛŒÛ Ú©Ø±ÛŒÚºÛ”",
    examples=[
        ["Ù…ÛŒÚº Ø¢Ø¬ Ø¨ÛØª Ø®ÙˆØ´ ÛÙˆÚº"], 
        ["ÛŒÛ ÙÛŒÙ„Ù… Ø¨Ø§Ù„Ú©Ù„ Ø§Ú†Ú¾ÛŒ Ù†ÛÛŒÚº ØªÚ¾ÛŒ"],
        ["Ú©Ú¾Ø§Ù†Ø§ Ø°Ø§Ø¦Ù‚Û Ø¯Ø§Ø± ØªÚ¾Ø§ Ù…Ú¯Ø± Ù…ÛÙ†Ú¯Ø§ ØªÚ¾Ø§"]
    ],
    allow_flagging="never",
    theme=gr.themes.Soft()
)

def process_output(prediction):
    """Transform output for Gradio components"""
    if prediction["success"]:
        return (
            prediction["sentiment"],  # For Label 1
            prediction["confidence"], # For Label 2
            ""                        # Hide details box
        )
    return (
        "Error", 
        "0%", 
        f"âŒ {prediction['error']}"  # Show error in details box
    )

# Reconfigure to use custom output processing
demo = gr.Interface(
    fn=analyze,
    inputs=demo.inputs,
    outputs=demo.outputs,
    examples=demo.examples,
    title=demo.title,
    description=demo.description,
    theme=demo.theme,
    allow_flagging="never",
    interpretation=None,
    live=False
)

# Launch configuration optimized for Hugging Face Spaces
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        debug=True,
        share=True
    )